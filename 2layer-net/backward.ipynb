{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from net import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create XOR dataset\n",
    "X = np.array([[0, 0, 1, 1],\n",
    "              [0, 1, 0, 1]])  # 2x4 matrix: 2 input features, 4 training examples\n",
    "y = np.array([[0, 1, 1, 0]])  # 1x4 matrix: XOR outputs\n",
    "\n",
    "# Initialize neural network\n",
    "# input_dim=2 (2 input features)\n",
    "# hidden_dim=4 (4 neurons in hidden layer)\n",
    "# output_dim=1 (1 output - binary classification)\n",
    "nn = NeuralNetwork(input_dim=2, hidden_dim=4, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the neural network...\n",
      "Epoch 0, Loss: 0.00921985433573284\n",
      "Epoch 100, Loss: 0.009205783029033873\n",
      "Epoch 200, Loss: 0.009191749691842862\n",
      "Epoch 300, Loss: 0.009177754180928978\n",
      "Epoch 400, Loss: 0.009163796353744997\n",
      "Epoch 500, Loss: 0.00914987606842352\n",
      "Epoch 600, Loss: 0.009135993183772999\n",
      "Epoch 700, Loss: 0.009122147559273883\n",
      "Epoch 800, Loss: 0.009108339055074913\n",
      "Epoch 900, Loss: 0.009094567531989192\n",
      "Epoch 1000, Loss: 0.009080832851490457\n",
      "Epoch 1100, Loss: 0.009067134875709317\n",
      "Epoch 1200, Loss: 0.009053473467429546\n",
      "Epoch 1300, Loss: 0.009039848490084355\n",
      "Epoch 1400, Loss: 0.009026259807752865\n",
      "Epoch 1500, Loss: 0.009012707285156112\n",
      "Epoch 1600, Loss: 0.008999190787653781\n",
      "Epoch 1700, Loss: 0.008985710181240369\n",
      "Epoch 1800, Loss: 0.008972265332541746\n",
      "Epoch 1900, Loss: 0.008958856108811463\n",
      "Epoch 2000, Loss: 0.008945482377927274\n",
      "Epoch 2100, Loss: 0.008932144008387724\n",
      "Epoch 2200, Loss: 0.008918840869308445\n",
      "Epoch 2300, Loss: 0.008905572830418922\n",
      "Epoch 2400, Loss: 0.008892339762058854\n",
      "Epoch 2500, Loss: 0.008879141535174807\n",
      "Epoch 2600, Loss: 0.008865978021316914\n",
      "Epoch 2700, Loss: 0.008852849092635305\n",
      "Epoch 2800, Loss: 0.008839754621876842\n",
      "Epoch 2900, Loss: 0.008826694482381858\n",
      "Epoch 3000, Loss: 0.008813668548080699\n",
      "Epoch 3100, Loss: 0.008800676693490567\n",
      "Epoch 3200, Loss: 0.00878771879371216\n",
      "Epoch 3300, Loss: 0.008774794724426395\n",
      "Epoch 3400, Loss: 0.008761904361891299\n",
      "Epoch 3500, Loss: 0.008749047582938697\n",
      "Epoch 3600, Loss: 0.008736224264971072\n",
      "Epoch 3700, Loss: 0.008723434285958412\n",
      "Epoch 3800, Loss: 0.008710677524434936\n",
      "Epoch 3900, Loss: 0.0086979538594962\n",
      "Epoch 4000, Loss: 0.008685263170795753\n",
      "Epoch 4100, Loss: 0.008672605338542205\n",
      "Epoch 4200, Loss: 0.008659980243496089\n",
      "Epoch 4300, Loss: 0.008647387766966847\n",
      "Epoch 4400, Loss: 0.008634827790809695\n",
      "Epoch 4500, Loss: 0.008622300197422857\n",
      "Epoch 4600, Loss: 0.008609804869744272\n",
      "Epoch 4700, Loss: 0.00859734169124887\n",
      "Epoch 4800, Loss: 0.008584910545945517\n",
      "Epoch 4900, Loss: 0.008572511318374032\n",
      "Epoch 5000, Loss: 0.008560143893602346\n",
      "Epoch 5100, Loss: 0.00854780815722362\n",
      "Epoch 5200, Loss: 0.008535503995353294\n",
      "Epoch 5300, Loss: 0.008523231294626251\n",
      "Epoch 5400, Loss: 0.008510989942194075\n",
      "Epoch 5500, Loss: 0.00849877982572203\n",
      "Epoch 5600, Loss: 0.008486600833386464\n",
      "Epoch 5700, Loss: 0.008474452853871836\n",
      "Epoch 5800, Loss: 0.00846233577636814\n",
      "Epoch 5900, Loss: 0.008450249490567944\n",
      "Epoch 6000, Loss: 0.008438193886663763\n",
      "Epoch 6100, Loss: 0.008426168855345398\n",
      "Epoch 6200, Loss: 0.008414174287797142\n",
      "Epoch 6300, Loss: 0.008402210075695114\n",
      "Epoch 6400, Loss: 0.008390276111204556\n",
      "Epoch 6500, Loss: 0.008378372286977277\n",
      "Epoch 6600, Loss: 0.00836649849614899\n",
      "Epoch 6700, Loss: 0.008354654632336592\n",
      "Epoch 6800, Loss: 0.008342840589635716\n",
      "Epoch 6900, Loss: 0.008331056262617991\n",
      "Epoch 7000, Loss: 0.00831930154632865\n",
      "Epoch 7100, Loss: 0.008307576336283817\n",
      "Epoch 7200, Loss: 0.008295880528468056\n",
      "Epoch 7300, Loss: 0.008284214019331783\n",
      "Epoch 7400, Loss: 0.008272576705788858\n",
      "Epoch 7500, Loss: 0.008260968485214008\n",
      "Epoch 7600, Loss: 0.0082493892554404\n",
      "Epoch 7700, Loss: 0.008237838914757182\n",
      "Epoch 7800, Loss: 0.008226317361906984\n",
      "Epoch 7900, Loss: 0.008214824496083505\n",
      "Epoch 8000, Loss: 0.008203360216929242\n",
      "Epoch 8100, Loss: 0.008191924424532841\n",
      "Epoch 8200, Loss: 0.008180517019426934\n",
      "Epoch 8300, Loss: 0.008169137902585633\n",
      "Epoch 8400, Loss: 0.008157786975422205\n",
      "Epoch 8500, Loss: 0.008146464139786862\n",
      "Epoch 8600, Loss: 0.008135169297964186\n",
      "Epoch 8700, Loss: 0.008123902352671011\n",
      "Epoch 8800, Loss: 0.008112663207054076\n",
      "Epoch 8900, Loss: 0.008101451764687727\n",
      "Epoch 9000, Loss: 0.008090267929571673\n",
      "Epoch 9100, Loss: 0.008079111606128654\n",
      "Epoch 9200, Loss: 0.00806798269920236\n",
      "Epoch 9300, Loss: 0.008056881114055049\n",
      "Epoch 9400, Loss: 0.008045806756365376\n",
      "Epoch 9500, Loss: 0.008034759532226248\n",
      "Epoch 9600, Loss: 0.008023739348142524\n",
      "Epoch 9700, Loss: 0.008012746111028984\n",
      "Epoch 9800, Loss: 0.008001779728208085\n",
      "Epoch 9900, Loss: 0.007990840107407804\n",
      "Epoch 10000, Loss: 0.007979927156759528\n",
      "Epoch 10100, Loss: 0.007969040784795958\n",
      "Epoch 10200, Loss: 0.007958180900448952\n",
      "Epoch 10300, Loss: 0.007947347413047479\n",
      "Epoch 10400, Loss: 0.007936540232315471\n",
      "Epoch 10500, Loss: 0.007925759268369855\n",
      "Epoch 10600, Loss: 0.007915004431718387\n",
      "Epoch 10700, Loss: 0.007904275633257636\n",
      "Epoch 10800, Loss: 0.007893572784271049\n",
      "Epoch 10900, Loss: 0.007882895796426802\n",
      "Epoch 11000, Loss: 0.007872244581775809\n",
      "Epoch 11100, Loss: 0.007861619052749853\n",
      "Epoch 11200, Loss: 0.007851019122159455\n",
      "Epoch 11300, Loss: 0.007840444703191968\n",
      "Epoch 11400, Loss: 0.007829895709409585\n",
      "Epoch 11500, Loss: 0.007819372054747455\n",
      "Epoch 11600, Loss: 0.0078088736535117005\n",
      "Epoch 11700, Loss: 0.007798400420377462\n",
      "Epoch 11800, Loss: 0.007787952270387068\n",
      "Epoch 11900, Loss: 0.007777529118948079\n",
      "Epoch 12000, Loss: 0.007767130881831379\n",
      "Epoch 12100, Loss: 0.007756757475169329\n",
      "Epoch 12200, Loss: 0.00774640881545393\n",
      "Epoch 12300, Loss: 0.007736084819534927\n",
      "Epoch 12400, Loss: 0.0077257854046179335\n",
      "Epoch 12500, Loss: 0.007715510488262702\n",
      "Epoch 12600, Loss: 0.007705259988381121\n",
      "Epoch 12700, Loss: 0.00769503382323564\n",
      "Epoch 12800, Loss: 0.007684831911437271\n",
      "Epoch 12900, Loss: 0.007674654171943885\n",
      "Epoch 13000, Loss: 0.007664500524058422\n",
      "Epoch 13100, Loss: 0.007654370887427124\n",
      "Epoch 13200, Loss: 0.007644265182037762\n",
      "Epoch 13300, Loss: 0.0076341833282178835\n",
      "Epoch 13400, Loss: 0.007624125246633106\n",
      "Epoch 13500, Loss: 0.007614090858285339\n",
      "Epoch 13600, Loss: 0.00760408008451118\n",
      "Epoch 13700, Loss: 0.007594092846980051\n",
      "Epoch 13800, Loss: 0.007584129067692579\n",
      "Epoch 13900, Loss: 0.007574188668978915\n",
      "Epoch 14000, Loss: 0.0075642715734970875\n",
      "Epoch 14100, Loss: 0.00755437770423123\n",
      "Epoch 14200, Loss: 0.007544506984490025\n",
      "Epoch 14300, Loss: 0.007534659337905055\n",
      "Epoch 14400, Loss: 0.007524834688429086\n",
      "Epoch 14500, Loss: 0.0075150329603344635\n",
      "Epoch 14600, Loss: 0.007505254078211567\n",
      "Epoch 14700, Loss: 0.007495497966967137\n",
      "Epoch 14800, Loss: 0.007485764551822691\n",
      "Epoch 14900, Loss: 0.00747605375831291\n",
      "Epoch 15000, Loss: 0.00746636551228409\n",
      "Epoch 15100, Loss: 0.007456699739892559\n",
      "Epoch 15200, Loss: 0.007447056367603089\n",
      "Epoch 15300, Loss: 0.007437435322187422\n",
      "Epoch 15400, Loss: 0.007427836530722629\n",
      "Epoch 15500, Loss: 0.007418259920589627\n",
      "Epoch 15600, Loss: 0.007408705419471647\n",
      "Epoch 15700, Loss: 0.007399172955352701\n",
      "Epoch 15800, Loss: 0.007389662456516146\n",
      "Epoch 15900, Loss: 0.0073801738515430135\n",
      "Epoch 16000, Loss: 0.007370707069310737\n",
      "Epoch 16100, Loss: 0.0073612620389915204\n",
      "Epoch 16200, Loss: 0.007351838690050858\n",
      "Epoch 16300, Loss: 0.00734243695224622\n",
      "Epoch 16400, Loss: 0.007333056755625398\n",
      "Epoch 16500, Loss: 0.007323698030525244\n",
      "Epoch 16600, Loss: 0.007314360707570038\n",
      "Epoch 16700, Loss: 0.007305044717670246\n",
      "Epoch 16800, Loss: 0.007295749992020946\n",
      "Epoch 16900, Loss: 0.0072864764621005385\n",
      "Epoch 17000, Loss: 0.007277224059669225\n",
      "Epoch 17100, Loss: 0.007267992716767693\n",
      "Epoch 17200, Loss: 0.007258782365715672\n",
      "Epoch 17300, Loss: 0.007249592939110578\n",
      "Epoch 17400, Loss: 0.007240424369826179\n",
      "Epoch 17500, Loss: 0.007231276591011134\n",
      "Epoch 17600, Loss: 0.0072221495360876835\n",
      "Epoch 17700, Loss: 0.007213043138750358\n",
      "Epoch 17800, Loss: 0.007203957332964507\n",
      "Epoch 17900, Loss: 0.007194892052965102\n",
      "Epoch 18000, Loss: 0.007185847233255266\n",
      "Epoch 18100, Loss: 0.007176822808605101\n",
      "Epoch 18200, Loss: 0.00716781871405024\n",
      "Epoch 18300, Loss: 0.007158834884890653\n",
      "Epoch 18400, Loss: 0.007149871256689292\n",
      "Epoch 18500, Loss: 0.007140927765270768\n",
      "Epoch 18600, Loss: 0.007132004346720153\n",
      "Epoch 18700, Loss: 0.00712310093738166\n",
      "Epoch 18800, Loss: 0.0071142174738573405\n",
      "Epoch 18900, Loss: 0.007105353893005902\n",
      "Epoch 19000, Loss: 0.00709651013194139\n",
      "Epoch 19100, Loss: 0.007087686128031932\n",
      "Epoch 19200, Loss: 0.007078881818898552\n",
      "Epoch 19300, Loss: 0.007070097142413961\n",
      "Epoch 19400, Loss: 0.0070613320367012376\n",
      "Epoch 19500, Loss: 0.007052586440132661\n",
      "Epoch 19600, Loss: 0.007043860291328514\n",
      "Epoch 19700, Loss: 0.007035153529155809\n",
      "Epoch 19800, Loss: 0.007026466092727201\n",
      "Epoch 19900, Loss: 0.007017797921399639\n",
      "Epoch 20000, Loss: 0.007009148954773408\n",
      "Epoch 20100, Loss: 0.007000519132690761\n",
      "Epoch 20200, Loss: 0.006991908395234757\n",
      "Epoch 20300, Loss: 0.006983316682728207\n",
      "Epoch 20400, Loss: 0.006974743935732449\n",
      "Epoch 20500, Loss: 0.006966190095046171\n",
      "Epoch 20600, Loss: 0.006957655101704343\n",
      "Epoch 20700, Loss: 0.006949138896976981\n",
      "Epoch 20800, Loss: 0.006940641422368127\n",
      "Epoch 20900, Loss: 0.0069321626196146135\n",
      "Epoch 21000, Loss: 0.006923702430685\n",
      "Epoch 21100, Loss: 0.006915260797778427\n",
      "Epoch 21200, Loss: 0.0069068376633235964\n",
      "Epoch 21300, Loss: 0.006898432969977575\n",
      "Epoch 21400, Loss: 0.00689004666062476\n",
      "Epoch 21500, Loss: 0.006881678678375709\n",
      "Epoch 21600, Loss: 0.006873328966566156\n",
      "Epoch 21700, Loss: 0.00686499746875586\n",
      "Epoch 21800, Loss: 0.0068566841287276\n",
      "Epoch 21900, Loss: 0.0068483888904860325\n",
      "Epoch 22000, Loss: 0.006840111698256717\n",
      "Epoch 22100, Loss: 0.006831852496485008\n",
      "Epoch 22200, Loss: 0.006823611229834995\n",
      "Epoch 22300, Loss: 0.006815387843188541\n",
      "Epoch 22400, Loss: 0.006807182281644145\n",
      "Epoch 22500, Loss: 0.006798994490515972\n",
      "Epoch 22600, Loss: 0.006790824415332838\n",
      "Epoch 22700, Loss: 0.006782672001837149\n",
      "Epoch 22800, Loss: 0.006774537195983912\n",
      "Epoch 22900, Loss: 0.006766419943939785\n",
      "Epoch 23000, Loss: 0.006758320192081911\n",
      "Epoch 23100, Loss: 0.0067502378869971165\n",
      "Epoch 23200, Loss: 0.006742172975480797\n",
      "Epoch 23300, Loss: 0.006734125404535991\n",
      "Epoch 23400, Loss: 0.0067260951213723615\n",
      "Epoch 23500, Loss: 0.0067180820734052404\n",
      "Epoch 23600, Loss: 0.00671008620825464\n",
      "Epoch 23700, Loss: 0.006702107473744348\n",
      "Epoch 23800, Loss: 0.006694145817900898\n",
      "Epoch 23900, Loss: 0.006686201188952655\n",
      "Epoch 24000, Loss: 0.006678273535328845\n",
      "Epoch 24100, Loss: 0.006670362805658594\n",
      "Epoch 24200, Loss: 0.006662468948770132\n",
      "Epoch 24300, Loss: 0.006654591913689634\n",
      "Epoch 24400, Loss: 0.00664673164964052\n",
      "Epoch 24500, Loss: 0.006638888106042339\n",
      "Epoch 24600, Loss: 0.0066310612325099355\n",
      "Epoch 24700, Loss: 0.006623250978852576\n",
      "Epoch 24800, Loss: 0.00661545729507302\n",
      "Epoch 24900, Loss: 0.0066076801313665265\n",
      "Epoch 25000, Loss: 0.006599919438120092\n",
      "Epoch 25100, Loss: 0.006592175165911518\n",
      "Epoch 25200, Loss: 0.006584447265508421\n",
      "Epoch 25300, Loss: 0.0065767356878675305\n",
      "Epoch 25400, Loss: 0.006569040384133624\n",
      "Epoch 25500, Loss: 0.006561361305638794\n",
      "Epoch 25600, Loss: 0.006553698403901502\n",
      "Epoch 25700, Loss: 0.0065460516306257415\n",
      "Epoch 25800, Loss: 0.006538420937700183\n",
      "Epoch 25900, Loss: 0.006530806277197353\n",
      "Epoch 26000, Loss: 0.006523207601372697\n",
      "Epoch 26100, Loss: 0.006515624862663766\n",
      "Epoch 26200, Loss: 0.006508058013689446\n",
      "Epoch 26300, Loss: 0.006500507007249031\n",
      "Epoch 26400, Loss: 0.0064929717963214326\n",
      "Epoch 26500, Loss: 0.006485452334064357\n",
      "Epoch 26600, Loss: 0.006477948573813472\n",
      "Epoch 26700, Loss: 0.006470460469081613\n",
      "Epoch 26800, Loss: 0.006462987973557848\n",
      "Epoch 26900, Loss: 0.006455531041106905\n",
      "Epoch 27000, Loss: 0.00644808962576815\n",
      "Epoch 27100, Loss: 0.006440663681754851\n",
      "Epoch 27200, Loss: 0.006433253163453426\n",
      "Epoch 27300, Loss: 0.006425858025422627\n",
      "Epoch 27400, Loss: 0.006418478222392714\n",
      "Epoch 27500, Loss: 0.006411113709264698\n",
      "Epoch 27600, Loss: 0.006403764441109601\n",
      "Epoch 27700, Loss: 0.0063964303731676025\n",
      "Epoch 27800, Loss: 0.006389111460847332\n",
      "Epoch 27900, Loss: 0.006381807659725057\n",
      "Epoch 28000, Loss: 0.0063745189255439575\n",
      "Epoch 28100, Loss: 0.006367245214213346\n",
      "Epoch 28200, Loss: 0.006359986481807904\n",
      "Epoch 28300, Loss: 0.006352742684566991\n",
      "Epoch 28400, Loss: 0.006345513778893759\n",
      "Epoch 28500, Loss: 0.006338299721354579\n",
      "Epoch 28600, Loss: 0.006331100468678177\n",
      "Epoch 28700, Loss: 0.006323915977754967\n",
      "Epoch 28800, Loss: 0.006316746205636279\n",
      "Epoch 28900, Loss: 0.006309591109533687\n",
      "Epoch 29000, Loss: 0.006302450646818188\n",
      "Epoch 29100, Loss: 0.006295324775019555\n",
      "Epoch 29200, Loss: 0.006288213451825646\n",
      "Epoch 29300, Loss: 0.0062811166350816095\n",
      "Epoch 29400, Loss: 0.00627403428278924\n",
      "Epoch 29500, Loss: 0.006266966353106209\n",
      "Epoch 29600, Loss: 0.006259912804345451\n",
      "Epoch 29700, Loss: 0.006252873594974411\n",
      "Epoch 29800, Loss: 0.00624584868361438\n",
      "Epoch 29900, Loss: 0.006238838029039714\n",
      "Epoch 30000, Loss: 0.006231841590177275\n",
      "Epoch 30100, Loss: 0.006224859326105711\n",
      "Epoch 30200, Loss: 0.006217891196054681\n",
      "Epoch 30300, Loss: 0.006210937159404323\n",
      "Epoch 30400, Loss: 0.006203997175684476\n",
      "Epoch 30500, Loss: 0.006197071204574058\n",
      "Epoch 30600, Loss: 0.006190159205900386\n",
      "Epoch 30700, Loss: 0.006183261139638502\n",
      "Epoch 30800, Loss: 0.006176376965910587\n",
      "Epoch 30900, Loss: 0.006169506644985193\n",
      "Epoch 31000, Loss: 0.006162650137276646\n",
      "Epoch 31100, Loss: 0.006155807403344461\n",
      "Epoch 31200, Loss: 0.006148978403892582\n",
      "Epoch 31300, Loss: 0.006142163099768824\n",
      "Epoch 31400, Loss: 0.006135361451964172\n",
      "Epoch 31500, Loss: 0.006128573421612184\n",
      "Epoch 31600, Loss: 0.0061217989699883825\n",
      "Epoch 31700, Loss: 0.006115038058509584\n",
      "Epoch 31800, Loss: 0.006108290648733295\n",
      "Epoch 31900, Loss: 0.006101556702357037\n",
      "Epoch 32000, Loss: 0.006094836181217877\n",
      "Epoch 32100, Loss: 0.006088129047291585\n",
      "Epoch 32200, Loss: 0.006081435262692256\n",
      "Epoch 32300, Loss: 0.00607475478967149\n",
      "Epoch 32400, Loss: 0.006068087590617976\n",
      "Epoch 32500, Loss: 0.0060614336280567244\n",
      "Epoch 32600, Loss: 0.006054792864648601\n",
      "Epoch 32700, Loss: 0.006048165263189647\n",
      "Epoch 32800, Loss: 0.0060415507866105195\n",
      "Epoch 32900, Loss: 0.006034949397975858\n",
      "Epoch 33000, Loss: 0.006028361060483768\n",
      "Epoch 33100, Loss: 0.006021785737465209\n",
      "Epoch 33200, Loss: 0.006015223392383358\n",
      "Epoch 33300, Loss: 0.006008673988833086\n",
      "Epoch 33400, Loss: 0.006002137490540415\n",
      "Epoch 33500, Loss: 0.005995613861361848\n",
      "Epoch 33600, Loss: 0.00598910306528389\n",
      "Epoch 33700, Loss: 0.0059826050664224355\n",
      "Epoch 33800, Loss: 0.005976119829022219\n",
      "Epoch 33900, Loss: 0.0059696473174562165\n",
      "Epoch 34000, Loss: 0.005963187496225146\n",
      "Epoch 34100, Loss: 0.005956740329956906\n",
      "Epoch 34200, Loss: 0.00595030578340596\n",
      "Epoch 34300, Loss: 0.005943883821452845\n",
      "Epoch 34400, Loss: 0.005937474409103622\n",
      "Epoch 34500, Loss: 0.005931077511489315\n",
      "Epoch 34600, Loss: 0.005924693093865371\n",
      "Epoch 34700, Loss: 0.005918321121611094\n",
      "Epoch 34800, Loss: 0.005911961560229185\n",
      "Epoch 34900, Loss: 0.005905614375345135\n",
      "Epoch 35000, Loss: 0.005899279532706753\n",
      "Epoch 35100, Loss: 0.005892956998183553\n",
      "Epoch 35200, Loss: 0.0058866467377663234\n",
      "Epoch 35300, Loss: 0.005880348717566553\n",
      "Epoch 35400, Loss: 0.005874062903815918\n",
      "Epoch 35500, Loss: 0.005867789262865784\n",
      "Epoch 35600, Loss: 0.005861527761186659\n",
      "Epoch 35700, Loss: 0.0058552783653677\n",
      "Epoch 35800, Loss: 0.005849041042116203\n",
      "Epoch 35900, Loss: 0.005842815758257123\n",
      "Epoch 36000, Loss: 0.005836602480732483\n",
      "Epoch 36100, Loss: 0.00583040117660099\n",
      "Epoch 36200, Loss: 0.005824211813037422\n",
      "Epoch 36300, Loss: 0.005818034357332232\n",
      "Epoch 36400, Loss: 0.005811868776890984\n",
      "Epoch 36500, Loss: 0.005805715039233875\n",
      "Epoch 36600, Loss: 0.005799573111995296\n",
      "Epoch 36700, Loss: 0.00579344296292324\n",
      "Epoch 36800, Loss: 0.0057873245598789366\n",
      "Epoch 36900, Loss: 0.00578121787083629\n",
      "Epoch 37000, Loss: 0.005775122863881428\n",
      "Epoch 37100, Loss: 0.005769039507212225\n",
      "Epoch 37200, Loss: 0.005762967769137758\n",
      "Epoch 37300, Loss: 0.005756907618077983\n",
      "Epoch 37400, Loss: 0.005750859022563171\n",
      "Epoch 37500, Loss: 0.0057448219512334295\n",
      "Epoch 37600, Loss: 0.005738796372838242\n",
      "Epoch 37700, Loss: 0.005732782256236032\n",
      "Epoch 37800, Loss: 0.005726779570393712\n",
      "Epoch 37900, Loss: 0.005720788284386144\n",
      "Epoch 38000, Loss: 0.005714808367395803\n",
      "Epoch 38100, Loss: 0.005708839788712194\n",
      "Epoch 38200, Loss: 0.005702882517731546\n",
      "Epoch 38300, Loss: 0.005696936523956218\n",
      "Epoch 38400, Loss: 0.0056910017769943415\n",
      "Epoch 38500, Loss: 0.005685078246559362\n",
      "Epoch 38600, Loss: 0.005679165902469558\n",
      "Epoch 38700, Loss: 0.005673264714647643\n",
      "Epoch 38800, Loss: 0.0056673746531203\n",
      "Epoch 38900, Loss: 0.0056614956880177555\n",
      "Epoch 39000, Loss: 0.005655627789573364\n",
      "Epoch 39100, Loss: 0.005649770928123122\n",
      "Epoch 39200, Loss: 0.005643925074105278\n",
      "Epoch 39300, Loss: 0.005638090198059938\n",
      "Epoch 39400, Loss: 0.005632266270628574\n",
      "Epoch 39500, Loss: 0.005626453262553597\n",
      "Epoch 39600, Loss: 0.0056206511446779935\n",
      "Epoch 39700, Loss: 0.005614859887944882\n",
      "Epoch 39800, Loss: 0.005609079463397088\n",
      "Epoch 39900, Loss: 0.005603309842176696\n",
      "Epoch 40000, Loss: 0.005597550995524698\n",
      "Epoch 40100, Loss: 0.005591802894780576\n",
      "Epoch 40200, Loss: 0.005586065511381826\n",
      "Epoch 40300, Loss: 0.0055803388168636\n",
      "Epoch 40400, Loss: 0.005574622782858328\n",
      "Epoch 40500, Loss: 0.0055689173810952635\n",
      "Epoch 40600, Loss: 0.005563222583400099\n",
      "Epoch 40700, Loss: 0.005557538361694538\n",
      "Epoch 40800, Loss: 0.005551864687995989\n",
      "Epoch 40900, Loss: 0.005546201534417043\n",
      "Epoch 41000, Loss: 0.005540548873165195\n",
      "Epoch 41100, Loss: 0.00553490667654232\n",
      "Epoch 41200, Loss: 0.0055292749169444984\n",
      "Epoch 41300, Loss: 0.005523653566861355\n",
      "Epoch 41400, Loss: 0.005518042598875876\n",
      "Epoch 41500, Loss: 0.005512441985663936\n",
      "Epoch 41600, Loss: 0.005506851699993954\n",
      "Epoch 41700, Loss: 0.0055012717147265335\n",
      "Epoch 41800, Loss: 0.005495702002813966\n",
      "Epoch 41900, Loss: 0.005490142537299989\n",
      "Epoch 42000, Loss: 0.00548459329131934\n",
      "Epoch 42100, Loss: 0.0054790542380974035\n",
      "Epoch 42200, Loss: 0.005473525350949821\n",
      "Epoch 42300, Loss: 0.005468006603282134\n",
      "Epoch 42400, Loss: 0.005462497968589464\n",
      "Epoch 42500, Loss: 0.005456999420456013\n",
      "Epoch 42600, Loss: 0.005451510932554851\n",
      "Epoch 42700, Loss: 0.0054460324786474775\n",
      "Epoch 42800, Loss: 0.005440564032583481\n",
      "Epoch 42900, Loss: 0.005435105568300119\n",
      "Epoch 43000, Loss: 0.005429657059822035\n",
      "Epoch 43100, Loss: 0.005424218481260887\n",
      "Epoch 43200, Loss: 0.005418789806814952\n",
      "Epoch 43300, Loss: 0.005413371010768879\n",
      "Epoch 43400, Loss: 0.005407962067493173\n",
      "Epoch 43500, Loss: 0.0054025629514440066\n",
      "Epoch 43600, Loss: 0.0053971736371627435\n",
      "Epoch 43700, Loss: 0.005391794099275707\n",
      "Epoch 43800, Loss: 0.005386424312493718\n",
      "Epoch 43900, Loss: 0.005381064251611838\n",
      "Epoch 44000, Loss: 0.005375713891509069\n",
      "Epoch 44100, Loss: 0.005370373207147854\n",
      "Epoch 44200, Loss: 0.00536504217357388\n",
      "Epoch 44300, Loss: 0.005359720765915704\n",
      "Epoch 44400, Loss: 0.005354408959384384\n",
      "Epoch 44500, Loss: 0.005349106729273184\n",
      "Epoch 44600, Loss: 0.005343814050957265\n",
      "Epoch 44700, Loss: 0.005338530899893284\n",
      "Epoch 44800, Loss: 0.005333257251619083\n",
      "Epoch 44900, Loss: 0.005327993081753429\n",
      "Epoch 45000, Loss: 0.005322738365995616\n",
      "Epoch 45100, Loss: 0.005317493080125154\n",
      "Epoch 45200, Loss: 0.005312257200001522\n",
      "Epoch 45300, Loss: 0.0053070307015636985\n",
      "Epoch 45400, Loss: 0.00530181356083\n",
      "Epoch 45500, Loss: 0.0052966057538976685\n",
      "Epoch 45600, Loss: 0.005291407256942575\n",
      "Epoch 45700, Loss: 0.005286218046218913\n",
      "Epoch 45800, Loss: 0.0052810380980588675\n",
      "Epoch 45900, Loss: 0.005275867388872344\n",
      "Epoch 46000, Loss: 0.005270705895146633\n",
      "Epoch 46100, Loss: 0.005265553593446072\n",
      "Epoch 46200, Loss: 0.005260410460411783\n",
      "Epoch 46300, Loss: 0.005255276472761323\n",
      "Epoch 46400, Loss: 0.005250151607288454\n",
      "Epoch 46500, Loss: 0.0052450358408627825\n",
      "Epoch 46600, Loss: 0.005239929150429423\n",
      "Epoch 46700, Loss: 0.005234831513008817\n",
      "Epoch 46800, Loss: 0.005229742905696267\n",
      "Epoch 46900, Loss: 0.005224663305661819\n",
      "Epoch 47000, Loss: 0.005219592690149811\n",
      "Epoch 47100, Loss: 0.005214531036478681\n",
      "Epoch 47200, Loss: 0.005209478322040628\n",
      "Epoch 47300, Loss: 0.005204434524301357\n",
      "Epoch 47400, Loss: 0.005199399620799711\n",
      "Epoch 47500, Loss: 0.005194373589147512\n",
      "Epoch 47600, Loss: 0.005189356407029102\n",
      "Epoch 47700, Loss: 0.005184348052201212\n",
      "Epoch 47800, Loss: 0.005179348502492578\n",
      "Epoch 47900, Loss: 0.005174357735803702\n",
      "Epoch 48000, Loss: 0.005169375730106581\n",
      "Epoch 48100, Loss: 0.005164402463444396\n",
      "Epoch 48200, Loss: 0.0051594379139312\n",
      "Epoch 48300, Loss: 0.00515448205975173\n",
      "Epoch 48400, Loss: 0.005149534879161062\n",
      "Epoch 48500, Loss: 0.005144596350484352\n",
      "Epoch 48600, Loss: 0.0051396664521165475\n",
      "Epoch 48700, Loss: 0.0051347451625221715\n",
      "Epoch 48800, Loss: 0.0051298324602349525\n",
      "Epoch 48900, Loss: 0.005124928323857617\n",
      "Epoch 49000, Loss: 0.00512003273206164\n",
      "Epoch 49100, Loss: 0.005115145663586931\n",
      "Epoch 49200, Loss: 0.005110267097241558\n",
      "Epoch 49300, Loss: 0.005105397011901549\n",
      "Epoch 49400, Loss: 0.005100535386510537\n",
      "Epoch 49500, Loss: 0.005095682200079559\n",
      "Epoch 49600, Loss: 0.0050908374316868095\n",
      "Epoch 49700, Loss: 0.005086001060477316\n",
      "Epoch 49800, Loss: 0.005081173065662687\n",
      "Epoch 49900, Loss: 0.0050763534265209145\n",
      "\n",
      "Testing the neural network...\n",
      "Input: [0, 0], Predicted Output: 0.0773\n",
      "Input: [0, 1], Predicted Output: 0.9287\n",
      "Input: [1, 0], Predicted Output: 0.9307\n",
      "Input: [1, 1], Predicted Output: 0.0664\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the network\n",
    "print(\"Training the neural network...\")\n",
    "nn.train(X, y, learning_rate=0.01, epochs=50000)\n",
    "\n",
    "# Test the network\n",
    "print(\"\\nTesting the neural network...\")\n",
    "test_cases = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "for test in test_cases:\n",
    "    x = np.array(test).reshape(2, 1)\n",
    "    prediction = nn.forward_propagation(x)\n",
    "    print(f\"Input: {test}, Predicted Output: {prediction[0][0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slackenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
